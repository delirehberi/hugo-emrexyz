<!doctype html><html><head lang=en><meta name=lightning content="fallingwhimsy946296@getalby.com"><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><title>LLM’lerin Geleceği ve Yazılım Geliştirmenin Dönüşümü - emre.xyz | @delirehberi</title><meta name=viewport content="width=device-width,initial-scale=1">
<meta name=description content="LLM'lerin gelecegi uzerine ongoruler. "><meta property="og:image" content><meta property="og:url" content="https://blog.emre.xyz/posts/llmlerin-gelisimi-ve-yazilim-gelistirmenin-donusumu/"><meta property="og:site_name" content="emre.xyz | @delirehberi"><meta property="og:title" content="LLM’lerin Geleceği ve Yazılım Geliştirmenin Dönüşümü"><meta property="og:description" content="LLM'lerin gelecegi uzerine ongoruler."><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-12-11T09:08:03-05:00"><meta property="article:modified_time" content="2025-12-11T09:08:03-05:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="LLM’lerin Geleceği ve Yazılım Geliştirmenin Dönüşümü"><meta name=twitter:description content="LLM'lerin gelecegi uzerine ongoruler."><script src=https://blog.emre.xyz/js/feather.min.js></script><link href=https://blog.emre.xyz/css/fonts.2c2227b81b1970a03e760aa2e6121cd01f87c88586803cbb282aa224720a765f.css rel=stylesheet><link rel=stylesheet type=text/css media=screen href=https://blog.emre.xyz/css/main.6a0f23ea50fd34b46fee262a5a68e17d458c51a2bc99ba1ba018065de6b180c3.css><link rel=stylesheet type=text/css media=screen href=https://blog.emre.xyz/css/ext.a79633986a21ab3daf02e6ccca6c7d985b6facd4b7dd3520b0c50336cfde916b.css><link id=darkModeStyle rel=stylesheet type=text/css href=https://blog.emre.xyz/css/dark.50b57e12d401420df23965fed157368aba37b76df0ecefd0b1ecd4da664f01a0.css disabled><script async src="https://www.googletagmanager.com/gtag/js?id=G-VLZVJMKPNJ"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-VLZVJMKPNJ")</script></head><body><div class=content><header><div class=main><a href=https://blog.emre.xyz/>emre.xyz | @delirehberi</a></div><nav><a href=/>main</a>
<a href=https://cal.emre.xyz>cal</a>
<a href=https://nostr.emre.xyz>nostr</a>
<a href=/til>til</a>
<a href=/about>me</a>
<a href=/subscribe>subscribe</a>
<a href=/resume.pdf>resume</a>
| <span id=dark-mode-toggle onclick=toggleTheme()><svg class="feather"><use href="/svg/feather-sprite.51cf5647cb1987f769b616558f2620fd9423d72058490231b391bf6aa3744b55.svg#sun"/></svg></span>
<script src=https://blog.emre.xyz/js/themetoggle.js></script><script type=text/javascript src=https://unpkg.com/zapthreads/dist/zapthreads.iife.js></script></nav></header><main><article><div class=post-container><div class=post-content><div class=title><h1 class=title>LLM’lerin Geleceği ve Yazılım Geliştirmenin Dönüşümü</h1><div class=meta>Posted on Dec 11, 2025</div></div><section class=body><p>Son birkaç yılda büyük dil modelleri (LLM’ler), yazılım geliştirme süreçlerini dramatik biçimde dönüştürmeye başladı. Kod tamamlama araçlarından otonom ajanlara, statik analizden güvenli sandbox ortamlarına kadar birçok yeni konsept artık günlük konuşmalarımızın parçası. Fakat bu dönüşüm aynı zamanda yeni sorular, yeni darboğazlar ve beklenmedik zorluklar da getiriyor.</p><p>Bu yazıda hem kendi deneyimlerimden hem de toplulukta farklı ortamlarda yapılan tartışmalardan yola çıkarak; LLM’lerin yazılım geliştirmede bugün nerede durduğunu ve gelecekte bizi nelerin beklediğini anlatmaya çalışacağım. Bunun için tabi ki yine Enis&rsquo;le yaptığımız bir konuşmadan yola çıktım.</p><p>Bu konuda 13 Aralık Cumartesi günü DevFest İzmir içerisinde de konuşacağım, vakti olanı beklerim.</p><h2 id=bugünkü-llmler-çok-iyi-kod-üretir-çok-kötü-karar-verir>Bugünkü LLM’ler: Çok iyi kod üretir, çok kötü karar verir</h2><p>Herkesin ortak deneyimi şu:</p><p>Bugünün modelleri, <strong>yeni bir proje açtığınızda</strong> müthiş bir üretkenlikle 1000 satır kod döktürebiliyor. Temiz sayfa, bilinen desenler, internette gördüğü milyonlarca örnek… Hepsi birleşince ilk taslak şaşırtıcı derecede iyi oluyor.</p><p>Ama proje ilerledikçe tablo değişiyor.</p><ul><li><p>Model, 1 satırlık basit bir input formatı hatasını <strong>günlerce yakalayamıyor</strong>.</p></li><li><p>Doküman orada duruyor ama ona “bakması gerektiğini” <strong>kendiliğinden anlayamıyor</strong>.</p></li><li><p>Hatta bazen çıkmaza girip A yöntemini deniyor → olmuyor → B yöntemini deniyor → o da olmuyor → ardından tekrar A’ya dönüyor.</p></li><li><p>Kodu ezbere yazdığı için yeni bağlamda yaratıcı düşünmesi gerekirken “bildiğini” tekrar etmeye başlıyor.</p></li></ul><p>Kısacası:<br><strong>LLM çok kod yazar, ama neden yazdığını bilmez.</strong></p><p>Bugün elimizdeki modeller hâlâ istatistiksel örüntü makineleri.</p><p>Reasoning var ama sınırlı; çoğu zaman “bu noktada durup dokümana bakmam gerekiyor” diye düşünecek bir öz bilinçleri yok.</p><p>Bu yüzden kod yazarken çoğu geliştirici kendini şu rolde buluyor:</p><blockquote><p>“Agent çalışıyor… ama 30 saniyede bir saçma bir şeyi bana soruyor. Kod yazmıyorum, bebek bakıyorum.”</p></blockquote><p>Yakın gelecekte değişmesi gereken ilk şey işte bu.</p><h2 id=secure-mode-ve-sandbox-asıl-devrim-burada-olacak>Secure Mode ve Sandbox: Asıl devrim burada olacak</h2><p>Bugün birçok araç “secure mode” gibi özellikler eklemeye başladı.<br>Ama bunlar hâlâ çok kısıtlı ve fazla interaktif. Her şeyi kullanıcıya soruyor; sonuçta işinizi kolaylaştırmıyor, zorlaştırıyor.</p><p>Oysa geliştiricilerin ihtiyacı çok net:</p><p><strong>LLM&rsquo;e kendi başına takılabileceği izole bir çalışma ortamı vermek.</strong></p><ul><li><p>Kodu yazacak</p></li><li><p>Derleyecek</p></li><li><p>Testleri çalıştıracak</p></li><li><p>Loglara bakacak</p></li><li><p>Dokümana göz atacak</p></li><li><p>StackOverflow/Docs tarzı bilgi tabanlarına danışacak</p></li><li><p>Gerekirse 3 ayrı yöntem deneyip hangisinin işe yaradığını kendi kendine görecek</p></li></ul><p>Ve tüm bunları bize sormadan yapacak.</p><p>Bir nevi “çalışan bir junior developer” gibi.</p><blockquote><p>“Ben yemeğe çıkıyorum, bu Haskell projesini haskell.nix ile derle.<br>20 dakika dene. Olmuyorsa raporla.”</p></blockquote><p>Bunun önündeki tek engel “güvenlik”.<br>LLM’i internete, sisteme, dosyalara bağlamak riskli olduğu için şirketler ve ürünler aşırı temkinli davranıyor.</p><p>Ama <strong>güvenli sandbox</strong> konsepti olgunlaştığında – ki bu çok yakın – LLM’lerin verimliliği bugünle kıyaslanamayacak kadar artacak.</p><h2 id=pythonda-mükemmel-haskellde-şaşkın-olmasının-sebebi-eğitim-verisi>Python’da Mükemmel, Haskell’de Şaşkın Olmasının Sebebi: Eğitim Verisi</h2><p>Bugün modeller Python’da harikalar yaratıyor, çünkü Python’a dair devasa bir eğitim külliyatı var.<br>Buna literatürde “Python Bias” bile deniyor.</p><p>Ama Haskell?<br>Az proje, küçük ekosistem, daha soyut yapılar, tür sistemi derinliği…</p><p>LLM’in aklı doğal olarak buralarda çok daha çabuk karışıyor.</p><p>Bu yüzden gelecekte en kritik ilerlemelerden biri <strong>dil ve ekosistem bazlı fine-tuning</strong> olacak.<br>Örneğin:</p><ul><li><p>“Haskell için optimize edilmiş LLM”</p></li><li><p>“Rust için eğitimli ajan”</p></li><li><p>“Nix ekosistemi için kendi kendine düzeltme yapabilen model”</p></li></ul><p>Bugün genel modellerle elde edemediğimiz güvenilirliği ancak böyle sağlayabileceğiz.</p><h2 id=sonuç-llm-devrimi-başladı-ama-daha-yolun-ilk-metresindeyiz>Sonuç: LLM devrimi başladı ama daha yolun ilk metresindeyiz</h2><p>Bugünün modelleri, bazen 1000 satır kodu 1 dakikada yazıp tek satırlık bir input hatasını 1 saatte çözemeyen tuhaf yaratıklar.</p><p>Ama doğru ortamları, doğru araçları ve doğru güvenlik katmanlarını sağladığımızda; yazılım geliştirmenin doğası gerçekten dönüşecek.</p><ul><li><p>Kod yazmak bitmeyecek.</p></li><li><p>Ama çalışmanın şekli, ritmi ve üretkenliği tamamen değişecek.</p></li></ul><p>Ve bu dönüşümün merkezinde hâlâ insan olacak:<br>Tasarım yapan, doğrulayan, yöneten, vizyon koyan.</p><p>LLM’ler ise çok güçlü, çok hızlı, ama hâlâ oldukça saf birer yardımcı olarak yanımızda yer alacak.</p><div class=nostr-id><a href=https://njump.me/nevent1qvzqqqr4guq3gamnwvaz7tmjv4kxz7fwv4khyefw0puh5qgkwaehxw309aex2mrp0yhxummnw3ezucnpdejqz9rhwden5te0wfjkccte9ejxzmt4wvhxjmcprpmhxue69uhhyetvv9ujuumwdae8gtnnda3kjctvqyxhwumn8ghj7mn0wvhxcmmvqyt8wumn8ghj7un9d3shjtnswf5k6ctv9ehx2aqppamhxue69uhkummnw3ezumt0d5q3vamnwvaz7tmjv4kxz7fwdehhxtnnda3kjctvqyd8wumn8ghj7ctjw35kxmr9wvhxcctev4erxtnwv4mhxqg7waehxw309akkcuewv94kgetwd9azuetyw5h8gu30dehhxarjqqsd4vkljd7sklzhf08g9u5nlrndql3pt7rw2clvla5jp5yaruk436cph0fcq>view in nostr/njump.me</a></div><zap-threads anchor=nevent1qvzqqqr4guq3gamnwvaz7tmjv4kxz7fwv4khyefw0puh5qgkwaehxw309aex2mrp0yhxummnw3ezucnpdejqz9rhwden5te0wfjkccte9ejxzmt4wvhxjmcprpmhxue69uhhyetvv9ujuumwdae8gtnnda3kjctvqyxhwumn8ghj7mn0wvhxcmmvqyt8wumn8ghj7un9d3shjtnswf5k6ctv9ehx2aqppamhxue69uhkummnw3ezumt0d5q3vamnwvaz7tmjv4kxz7fwdehhxtnnda3kjctvqyd8wumn8ghj7ctjw35kxmr9wvhxcctev4erxtnwv4mhxqg7waehxw309akkcuewv94kgetwd9azuetyw5h8gu30dehhxarjqqsd4vkljd7sklzhf08g9u5nlrndql3pt7rw2clvla5jp5yaruk436cph0fcq></section><div class=post-tags></div></div></div></article></main><footer><div style=display:flex><a class=soc target=_blank href=https://github.com/delirehberi rel=me title=GitHub><i data-feather=github></i></a>
<a class=border></a><a class=soc target=_blank href=https://youtube.com/EmreYILMAZ rel=me title=Youtube><i data-feather=youtube></i></a>
<a class=border></a><a class=soc target=_blank href=https://linkedin.com/in/delirehberi rel=me title=Linkedin><i data-feather=linkedin></i></a>
<a class=border></a><a class=soc target=_blank href=http://blog.emre.xyz/me.vcf rel=me title=VCF><i data-feather=phone></i></a>
<a class=border></a></div><div class=footer-info>2026 delirehberi | built with hugo</div></footer><script>feather.replace()</script></div></body></html>